---
title: "Project-6348-exam3"
author: "HS"
date: "2025-04-23"
output:
  html_document:
    df_print: paged
  word_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# Load the required libraries

library(readr)
library(dplyr)
library(ggplot2)
library(corrplot)
library(caret)
library(e1071)
library(tidyverse)
library(factoextra)
library(randomForest)
library(nnet)

```


## Data Pre-Processing

```{r  }
# Load the file with the list of feature names
features <- read.table("UCI HAR Dataset/features.txt", col.names = c("feature_id", "feature_name"))

# Load activity labels
activity_labels <- read.table("UCI HAR Dataset/activity_labels.txt", col.names = c("activity_id", "activity"))

# Load the training data
train_x <- read.table("UCI HAR Dataset/train/X_train.txt", col.names = features$feature_name)
train_y <- read.table("UCI HAR Dataset/train/y_train.txt", col.names = "activity_id")
train_subject <- read.table("UCI HAR Dataset/train/subject_train.txt", col.names = "subject")

# Combine training data
train_x <- cbind(train_subject, train_x)
train_y$activity_id <- factor(train_y$activity_id)
train_data <- cbind(train_x, train_y)

# Load the test data
test_x <- read.table("UCI HAR Dataset/test/X_test.txt", col.names = features$feature_name)
test_y <- read.table("UCI HAR Dataset/test/y_test.txt", col.names = "activity_id")
test_subject <- read.table("UCI HAR Dataset/test/subject_test.txt", col.names = "subject")

# Combine test data
test_x <- cbind(test_subject, test_x)
test_y$activity_id <- factor(test_y$activity_id)
test_data <- cbind(test_x, test_y)

# Combine training and test sets
full_data <- rbind(train_data, test_data)
full_data$activity_id <- factor(full_data$activity_id)

# Merge with activity labels
full_data <- merge(full_data, activity_labels, by = "activity_id")

# Check the dimensions of the combined dataset
dim(full_data)
```

```{r  }
#Pre-processing
# Check for missing values
missing_values <- colSums(is.na(full_data))
cat("Total missing values:", sum(missing_values), "\n")

# Handle duplicate column names if any exist
colnames(full_data) <- make.names(colnames(full_data), unique = TRUE)
```


```{r}
features$clean_name <- make.names(features$feature_name, unique = TRUE)
mean_std_features <- grep("mean|std", features$clean_name, value = TRUE)

```


```{r}
length(mean_std_features)
```

```{r}
colnames(full_data)
```


```{r}
intersect(colnames(full_data), mean_std_features)
```


```{r}
#print(mean_std_features)
selected_data <- full_data[, c("subject", "activity_id", "activity", mean_std_features)]
str(selected_data)

```


```{r}
summary(full_data)
```


```{r  }
numeric_data <- selected_data %>% select(where(is.numeric))
colMeans(numeric_data)
```


```{r}
numeric_data <- selected_data[, sapply(selected_data, is.numeric)]
colMeans(numeric_data)

```



```{r}
colMeans(selected_data[,-c(1,2,3)])

```


```{r  }
head(features$feature_name)

```
```{r}
print(colnames(full_data))
print(mean_std_features)

features$clean_name <- make.names(features$feature_name, unique = TRUE)
mean_std_features <- grep("mean\\(\\)|std\\(\\)", features$clean_name, value = TRUE)

selected_data <- full_data[, c("subject", "activity_id", "activity", mean_std_features)]

# Convert subject to factor
full_data$subject <- as.factor(full_data$subject)

# Make sure activity is properly coded as a factor
full_data$activity <- as.factor(full_data$activity)

# Clean feature names
features$clean_name <- make.names(features$feature_name, unique = TRUE)

# Extract only mean and std features for potentially cleaner analysis
mean_std_features <- grep("mean\\(\\)|std\\(\\)", features$clean_name, value = TRUE)

# Verify if mean_std_features exist in full_data
valid_features <- intersect(colnames(full_data), mean_std_features)

# Select columns
selected_data <- full_data[, c("subject", "activity_id", "activity", valid_features)]

# Check structure of the selected data
str(selected_data)

```


```{r  }
# Convert subject to factor
full_data$subject <- as.factor(full_data$subject)

# Make sure activity is properly coded as a factor
full_data$activity <- as.factor(full_data$activity)

# Extract only mean and std features for potentially cleaner analysis
mean_std_features <- grep("mean\\(\\)|std\\(\\)", features$feature_name, value = TRUE)
selected_data <- full_data[, c("subject", "activity_id", "activity", mean_std_features)]

# Check structure of the selected data
#str(selected_data[, 1:10])
```


```{r  }
pca <- prcomp(numeric_data, center = TRUE, scale. = TRUE)

```


```{r}
pca_data <- data.frame(pca$x, activity = selected_data$activity)
train_index <- createDataPartition(pca_data$activity, p = 0.7, list = FALSE)
train_set <- pca_data[train_index, ]
test_set <- pca_data[-train_index, ]

# Train Logistic Regression (Baseline)
logistic_model <- train(activity ~ ., data = train_set, method = "glm")
logistic_pred <- predict(logistic_model, test_set)
confusionMatrix(logistic_pred, test_set$activity)

```

```{r}

# Train Multinomial Logistic Regression (Multiclass)
multinom_model <- train(activity ~ ., data = train_set, method = "multinom")

# Predict on test set
multinom_predictions <- predict(multinom_model, newdata = test_set)

# Evaluate the model
confusionMatrix(multinom_predictions, test_set$activity)

```

```{r}
# Perform PCA
pca <- prcomp(numeric_data, center = TRUE, scale. = TRUE)
pca_data <- data.frame(pca$x, activity = selected_data$activity)

# Split the data into training and test sets
train_index <- createDataPartition(pca_data$activity, p = 0.7, list = FALSE)
train_set <- pca_data[train_index, ]
test_set <- pca_data[-train_index, ]

# Train Multinomial Logistic Regression (Multiclass) with regularization
multinom_model <- train(activity ~ ., data = train_set, method = "multinom", maxit = 100, trace = TRUE, decay = 0.1)

# Predict on test set
multinom_predictions <- predict(multinom_model, newdata = test_set)

# Evaluate the model
confusionMatrix(multinom_predictions, test_set$activity)




```





```{r  }
pca <- prcomp(selected_data[, -c(1,2)], center = TRUE, scale. = TRUE)
fviz_eig(pca) # Scree plot for variance explained
fviz_pca_ind(pca, habillage = selected_data$activity) # PCA clustering

```

```{r  }

```


```{r  }

```